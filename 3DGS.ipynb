{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D GAUSSIAN SPLATTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    " 3D Gaussian Splatting is a recent technique for novel view synthesis that achieves real-time rendering with state-of-the-art quality​. It replaces expensive neural networks with a fast point-based representation: the scene is represented as millions of tiny 3D Gaussians (“splats”), each with a position, anisotropic covariance (shape), color (with view-dependent effects), and opacity.\n",
    "\n",
    "The method has three key components​: \n",
    "1. starting from a sparse set of points (e.g. from COLMAP Structure-from-Motion), initialize a radiance field as 3D Gaussians instead of voxels or meshes; \n",
    "2. interleave optimization of Gaussian parameters (position, covariance, color) with adaptive density control (adding or removing Gaussians) to progressively refine scene geometry; \n",
    "3. use a fast differentiable rasterizer that projects these 3D Gaussians to the image plane and blends them with proper ordering (front-to-back alpha compositing) for real-time rendering​. \n",
    "\n",
    "\n",
    "We will reimplement the core of this pipeline step by step in Python/PyTorch, explaining each part in detail and linking to the corresponding parts of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing (Input Preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare the input data: a set of calibrated images of the scene and an initial sparse 3D point cloud (if available). The sparse points typically come from a Structure-from-Motion (SfM) reconstruction (e.g. COLMAP) of the scene. These SfM points will serve as initial Gaussian locations, providing a rough geometry prior for optimization​. If an initial point cloud is not available (e.g. for synthetic scenes), we can start with a random distribution of points, but using real SfM points speeds up convergence and improves quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-02 16:51:24--  https://raw.githubusercontent.com/colmap/colmap/dev/scripts/python/read_write_model.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22534 (22K) [text/plain]\n",
      "Saving to: ‘read_write_model.py.2’\n",
      "\n",
      "read_write_model.py 100%[===================>]  22,01K  --.-KB/s    in 0,002s  \n",
      "\n",
      "2025-03-02 16:51:24 (11,9 MB/s) - ‘read_write_model.py.2’ saved [22534/22534]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First lets get COLMAP's read/write python utilities\n",
    "\n",
    "!wget https://raw.githubusercontent.com/colmap/colmap/dev/scripts/python/read_write_model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: (206613, 3)\n",
      "Num images loaded: 292\n",
      "Camera poses: 292\n",
      "Camera intrinsics: 292\n",
      "Image files: 292\n",
      "Images loaded: 292\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import read_write_model  # from colmap scripts\n",
    "\n",
    "def load_mipnerf_scene(scene_path, resolution_folder=\"images_8\"):\n",
    "    sparse_path = os.path.join(scene_path, \"sparse\", \"0\")\n",
    "    cameras_bin = os.path.join(sparse_path, \"cameras.bin\")\n",
    "    images_bin  = os.path.join(sparse_path, \"images.bin\")\n",
    "    points3d_bin= os.path.join(sparse_path, \"points3D.bin\")\n",
    "    \n",
    "    # Read colmap binaries\n",
    "    cameras_dict = read_write_model.read_cameras_binary(cameras_bin)\n",
    "    images_dict  = read_write_model.read_images_binary(images_bin)\n",
    "    points3D_dict= read_write_model.read_points3D_binary(points3d_bin)\n",
    "    \n",
    "    # Convert points\n",
    "    points_world = []\n",
    "    points_color = []\n",
    "    for pid, p3d_data in points3D_dict.items():\n",
    "        points_world.append(p3d_data.xyz)\n",
    "        points_color.append(p3d_data.rgb)\n",
    "    points_world = np.array(points_world, dtype=np.float32)\n",
    "    points_color = np.array(points_color, dtype=np.uint8)\n",
    "    \n",
    "    # Prepare lists for camera extrinsics & intrinsics\n",
    "    camera_poses = []\n",
    "    image_files = []\n",
    "    camera_intrinsics = []\n",
    "    \n",
    "    for img_id, img_data in images_dict.items():\n",
    "        qvec = img_data.qvec\n",
    "        tvec = img_data.tvec\n",
    "        cam_id = img_data.camera_id\n",
    "        fname = img_data.name\n",
    "        \n",
    "        # rotation: world->cam\n",
    "        # (We can convert quaternion->rotation matrix if needed.)\n",
    "        \n",
    "        # intrinsics from cameras_dict\n",
    "        cam_data = cameras_dict[cam_id]\n",
    "        fx, fy, cx, cy = cam_data.params[:4]  # if pinhole\n",
    "        w, h = cam_data.width, cam_data.height\n",
    "        \n",
    "        # store\n",
    "        camera_poses.append((qvec, tvec, cam_id))\n",
    "        image_files.append(fname)\n",
    "        camera_intrinsics.append((fx, fy, cx, cy, w, h))\n",
    "    \n",
    "    # Now load images from resolution_folder\n",
    "    images_path = os.path.join(scene_path, resolution_folder)\n",
    "    loaded_images = []\n",
    "    for fname in image_files:\n",
    "        full_path = os.path.join(images_path, fname)\n",
    "        img = cv2.imread(full_path)\n",
    "        if img is None:\n",
    "            print(\"Warning: cannot load\", full_path)\n",
    "            loaded_images.append(None)\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)/255.0\n",
    "        loaded_images.append(img)\n",
    "    \n",
    "    return {\n",
    "        \"points_world\": points_world,\n",
    "        \"points_color\": points_color,\n",
    "        \"camera_poses\": camera_poses,      # list of (qvec, tvec, cam_id)\n",
    "        \"camera_intrinsics\": camera_intrinsics,  # list of (fx, fy, cx, cy, w, h)\n",
    "        \"image_files\": image_files,\n",
    "        \"images\": loaded_images\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "scene_data = load_mipnerf_scene(\n",
    "    scene_path=\"/home/ndelafuente/3DCV/mipnerf360_dataset/bonsai\",\n",
    "    resolution_folder=\"images_8\"\n",
    ")\n",
    "print(\"Points:\", scene_data[\"points_world\"].shape)\n",
    "print(\"Num images loaded:\", len(scene_data[\"images\"]))\n",
    "\n",
    "#print more stats\n",
    "print(\"Camera poses:\", len(scene_data[\"camera_poses\"]))\n",
    "print(\"Camera intrinsics:\", len(scene_data[\"camera_intrinsics\"]))\n",
    "print(\"Image files:\", len(scene_data[\"image_files\"]))\n",
    "print(\"Images loaded:\", len(scene_data[\"images\"]))\n",
    "\n",
    "# Visualize a point cloud\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(scene_data[\"points_world\"][:,0], scene_data[\"points_world\"][:,1], scene_data[\"points_world\"][:,2], c=scene_data[\"points_color\"]/255.0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Representation (Scene Initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each 3D Gaussian is defined by a mean position, a covariance matrix, an opacity (alpha), and radiance (color with view-dependence)​. \n",
    " Rather than explicitly storing a full $3\\times3$ covariance matrix for each Gaussian (which must remain positive semi-definite), the paper parameterizes the covariance in a more stable way:\n",
    "\n",
    "- **Position** $\\mathbf{\\mu} \\in \\mathbb{R}^3$: the center of the Gaussian in world coordinates​.\n",
    "\n",
    "- **Covariance** $\\Sigma = R , \\text{diag}(s_x^2, s_y^2, s_z^2), R^T$: defined by a scaling vector $\\mathbf{s}=(s_x,s_y,s_z)$ giving the standard deviations along the Gaussian’s local axes, and a rotation $R$ (parameterized as a quaternion) giving the orientation of those axes in world space​. This is equivalent to an anisotropic 3D Gaussian ellipsoid oriented arbitrarily in space. Using $\\mathbf{s}$ and a unit quaternion for $R$ ensures the covariance is always positive semi-definite (since $s_i^2$ are positive)​.\n",
    "- **Opacity** $\\alpha \\in [0,1]$: a scalar weight controlling how much this Gaussian contributes to density/color along a ray​. In the rendering algorithm, $\\alpha$ will be used for alpha-blending (transparency) of the splats.\n",
    "- **Color coefficients:** Instead of a single RGB color, the method uses Spherical Harmonics (SH) to model view-dependent color​. Specifically, each Gaussian has coefficients for a low-order SH expansion (typically 2nd order, i.e. $l=0,1,2$) that produces an RGB radiance given a viewing direction​. Using SH allows the Gaussian to change color depending on the view (to capture specular highlights, etc.), similar to NeRF’s view-dependent emission. Following prior work (Plenoxels, Instant-NGP)​, 2nd-order SH means 9 coefficients per color channel (total 27 coefficients per Gaussian for RGB) if we include all terms up to $l=2$. (In some cases, one might use 3rd order/16 coefficients per channel​, but here we’ll use 2nd order for simplicity as used in the paper’s comparisons​.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/ndelafuente/miniconda3/envs/d-mae/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ndelafuente/miniconda3/envs/d-mae/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ndelafuente/miniconda3/envs/d-mae/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ndelafuente/miniconda3/envs/d-mae/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ndelafuente/miniconda3/envs/d-mae/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Gaussian parameters:\n",
      "  positions:    torch.Size([206613, 3])\n",
      "  log_scales:   torch.Size([206613, 3])\n",
      "  quaternions:  torch.Size([206613, 4])\n",
      "  sh_coeffs:    torch.Size([206613, 27])\n",
      "  alpha_params: torch.Size([206613])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Convert data to torch tensors\n",
    "points_world_torch = torch.tensor(scene_data[\"points_world\"], dtype=torch.float32)  # (N,3)\n",
    "colors_torch = torch.tensor(scene_data[\"points_color\"], dtype=torch.float32) / 255.0  # (N,3) normalized\n",
    "N = points_world_torch.shape[0]\n",
    "\n",
    "# Use scikit-learn's NearestNeighbors to avoid computing the full NxN distance matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit with all points; request 4 neighbors so that the first is self (if we did it with all points it'd be unfeasible)\n",
    "nbrs = NearestNeighbors(n_neighbors=4, algorithm='auto').fit(scene_data[\"points_world\"])\n",
    "distances, indices = nbrs.kneighbors(scene_data[\"points_world\"])\n",
    "# distances has shape (N,4); the first column is zero (self-distance)\n",
    "init_sigma_np = np.mean(distances[:,1:], axis=1)  # average distance to 3 nearest neighbors\n",
    "\n",
    "# Convert to torch tensor\n",
    "init_sigma = torch.tensor(init_sigma_np, dtype=torch.float32)\n",
    "\n",
    "# Initialize Gaussian parameters:\n",
    "\n",
    "# 1) Positions: directly from SfM points\n",
    "positions = points_world_torch.clone().detach().requires_grad_(True)\n",
    "\n",
    "# 2) Covariance scales (log_scales)\n",
    "#    We set log_scales so that exp(log_scale) equals the average nearest neighbor distance.\n",
    "log_scales_data = init_sigma.unsqueeze(1).expand(N, 3)  # shape (N,3)\n",
    "log_scales = log_scales_data.clone().detach().requires_grad_(True)\n",
    "\n",
    "# 3) Quaternions: initialize to identity (no rotation)\n",
    "quaternions_data = torch.zeros((N, 4), dtype=torch.float32)\n",
    "quaternions_data[:, 0] = 1.0\n",
    "quaternions = quaternions_data.clone().detach().requires_grad_(True)\n",
    "\n",
    "# 4) Spherical Harmonic Coefficients for color\n",
    "#    For 2nd-order SH: 9 coefficients per channel → 27 total\n",
    "sh_degree = 2\n",
    "n_basis = (sh_degree + 1) ** 2  # 9\n",
    "n_coeffs = n_basis * 3         # 27\n",
    "sh_data = torch.zeros((N, n_coeffs), dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    for i in range(N):\n",
    "        r, g, b = colors_torch[i]\n",
    "        sh_data[i, 0] = r    # DC term for red\n",
    "        sh_data[i, 9] = g    # DC term for green\n",
    "        sh_data[i, 18] = b   # DC term for blue\n",
    "sh_coeffs = sh_data.clone().detach().requires_grad_(True)\n",
    "\n",
    "# 5) Opacity (alpha) parameters: store as logits so that alpha = sigmoid(alpha_params)\n",
    "alpha_params = torch.full((N,), -4.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "print(\"Initialized Gaussian parameters:\")\n",
    "print(f\"  positions:    {positions.shape}\")\n",
    "print(f\"  log_scales:   {log_scales.shape}\")\n",
    "print(f\"  quaternions:  {quaternions.shape}\")\n",
    "print(f\"  sh_coeffs:    {sh_coeffs.shape}\")\n",
    "print(f\"  alpha_params: {alpha_params.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized Gaussian Parameters\n",
    "\n",
    "- **Positions** (`torch.Size([206613, 3])`):  \n",
    "  Each row is a 3D point \\(\\mathbf{\\mu} \\in \\mathbb{R}^3\\) in world space.  \n",
    "  We have 206,613 Gaussians in total, and each Gaussian’s center is initialized to one of the sparse SfM points obtained from COLMAP.\n",
    "\n",
    "- **Log Scales** (`torch.Size([206613, 3])`):  \n",
    "  Each row contains the logarithm of the scales \\(\\log(s_x, s_y, s_z)\\) along the three axes.  \n",
    "  By storing the scale parameters in log form, we ensure that when we compute \\(s = \\exp(\\text{log\\_scale})\\), the scales are always positive.  \n",
    "  The scales are initialized based on the average distance to the 3 nearest neighbors of each point. In regions where points are dense, the scales will be smaller; in sparser regions, they will be larger.\n",
    "\n",
    "- **Quaternions** (`torch.Size([206613, 4])`):  \n",
    "  Each row is a unit quaternion \\((w, x, y, z)\\) representing the orientation of the Gaussian’s local coordinate system.  \n",
    "  We initialize all quaternions to the identity quaternion \\((1, 0, 0, 0)\\), meaning no initial rotation is applied.  \n",
    "  During optimization, these quaternions will be updated and **re-normalized** to ensure they remain valid rotations.\n",
    "\n",
    "- **Spherical Harmonic Coefficients** (`torch.Size([206613, 27])`):  \n",
    "  We use a 2nd-order spherical harmonics (SH) expansion for color, which provides 9 coefficients per color channel \\((9 \\times 3 = 27)\\).  \n",
    "  These coefficients allow each Gaussian to model **view-dependent color** (capturing specular highlights, etc.).  \n",
    "  Initially, only the DC (constant) component is set using the point’s color, while the remaining coefficients are set to zero, meaning there is no view dependence at the start.\n",
    "\n",
    "- **Alpha Parameters** (`torch.Size([206613])`):  \n",
    "  This tensor stores the **logit** values for the opacity \\(\\alpha\\) of each Gaussian.  \n",
    "  The actual opacity is computed as \\(\\alpha = \\sigma(\\text{alpha\\_params})\\), where \\(\\sigma\\) is the sigmoid function, ensuring that \\(\\alpha\\) lies in the range \\([0,1]\\).  \n",
    "  We initialize these parameters with a negative value (here \\(-4.0\\)) so that the initial opacity is very low (approximately 1.8%), meaning the Gaussians start nearly transparent.  \n",
    "  During training, the opacity will be adjusted as needed.\n",
    "\n",
    "In summary, we now have a complete **PyTorch representation** of our scene as a collection of 206,613 Gaussians. Each Gaussian is defined by:\n",
    "\n",
    "- Its **position** (center) from the SfM points,\n",
    "- Its **anisotropic scale** (via log scales and a rotation given by the quaternion),\n",
    "- Its **view-dependent color** (via 27 SH coefficients),\n",
    "- Its **opacity** (via alpha parameters).\n",
    "\n",
    "This setup lays the groundwork for the next steps, where we’ll implement the **rendering** function and the **optimization** loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization (Training the Gaussian Radiance Field)\n",
    "\n",
    "Now that we've initialized the 3D Gaussian parameters, we want to optimize them so that when we render our scene from each training view, the rendered image matches the ground-truth photo. We'll do this in a standard \"training loop\" style:\n",
    "\n",
    "1. **Render** the scene from a given camera.\n",
    "2. **Compare** the rendered image to the ground truth (compute a loss).\n",
    "3. **Backprop** the error through our Gaussian parameters.\n",
    "4. **Update** the parameters with an optimizer (Adam).\n",
    "\n",
    "However, Gaussian Splatting includes two extra aspects:\n",
    "- **Interleaved Density Control** (adding/removing Gaussians).\n",
    "- **Fast Differentiable Rendering** (we'll implement a simplified version later).\n",
    "\n",
    "Below is code to set up the optimizer, define a simple MSE loss, and sketch the training loop. \n",
    "For the actual `render(...)` function, we'll provide a placeholder now and implement it fully in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def image_loss(pred, target):\n",
    "    \"\"\"\n",
    "    Simple MSE loss between pred and target images.\n",
    "    Both pred and target are assumed to be [H, W, 3] in [0, 1].\n",
    "    \"\"\"\n",
    "    return F.mse_loss(pred, target)\n",
    "\n",
    "# --- Hyperparameters for each parameter group ---\n",
    "lr_pos = 1e-3     # position\n",
    "lr_scale = 1e-3   # log_scales\n",
    "lr_quat = 1e-3    # quaternions\n",
    "lr_sh = 1e-2      # SH color coefficients\n",
    "lr_alpha = 5e-3   # alpha_params\n",
    "\n",
    "# Create an Adam optimizer with separate LR for each parameter group\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': positions,    'lr': lr_pos},\n",
    "    {'params': log_scales,   'lr': lr_scale},\n",
    "    {'params': quaternions,  'lr': lr_quat},\n",
    "    {'params': sh_coeffs,    'lr': lr_sh},\n",
    "    {'params': alpha_params, 'lr': lr_alpha},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder render function (we'll implement later).\n",
    "def render(R, t, fx, fy, cx, cy, positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "           width, height):\n",
    "    \"\"\"\n",
    "    R, t : Camera rotation (3x3) and translation (3,) for world->camera transform.\n",
    "    fx, fy, cx, cy : Camera intrinsics.\n",
    "    positions, log_scales, quaternions, alpha_params, sh_coeffs : 3D Gaussian parameters.\n",
    "    width, height : Desired render resolution.\n",
    "    \n",
    "    Returns: A dummy image tensor of shape [height, width, 3] in [0, 1].\n",
    "    \n",
    "    Note: We add a term that depends on 'positions' so that the output\n",
    "    has a grad_fn, ensuring gradients flow during backpropagation.\n",
    "    \"\"\"\n",
    "    dummy = torch.zeros((height, width, 3), dtype=torch.float32, device=positions.device)\n",
    "    # Force dependency on positions (this does nothing to the value but ensures grad_fn is attached)\n",
    "    dummy = dummy + positions.sum() * 0.0\n",
    "    return dummy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "pred_image.shape = torch.Size([260, 390, 3])\n",
      "image_gt_torch.shape = torch.Size([260, 390, 3])\n",
      "Training loop complete (dummy version). Next, we need a real 'render()' to see meaningful updates.\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop (simplified example) ---\n",
    "num_epochs = 1\n",
    "densify_interval = 100\n",
    "warmup_iters = 100\n",
    "\n",
    "train_images = scene_data[\"images\"]        # list of [H, W, 3] images (ground truth)\n",
    "camera_info = scene_data[\"camera_intrinsics\"]  # list of (fx, fy, cx, cy, w, h) per image\n",
    "camera_poses = scene_data[\"camera_poses\"]      # list of (qvec, tvec, cam_id)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for img_idx, image_gt in enumerate(train_images):\n",
    "        # Skip if image not loaded\n",
    "        if image_gt is None:\n",
    "            continue\n",
    "\n",
    "        # Convert the ground-truth image to a torch tensor on the same device as the Gaussians.\n",
    "        image_gt_torch = torch.tensor(image_gt, dtype=torch.float32, device=positions.device)\n",
    "        \n",
    "        # Use the shape of the ground truth to set render dimensions.\n",
    "        img_h, img_w = image_gt_torch.shape[0], image_gt_torch.shape[1]\n",
    "        \n",
    "        # Extract camera intrinsics from camera_info\n",
    "        fx, fy, cx, cy, _, _ = camera_info[img_idx]\n",
    "        \n",
    "        # For now, we assume identity rotation and zero translation as a placeholder.\n",
    "        R = torch.eye(3, device=positions.device)\n",
    "        t = torch.zeros(3, device=positions.device)\n",
    "        \n",
    "        # Render the current scene.\n",
    "        pred_image = render(R, t, fx, fy, cx, cy,\n",
    "                            positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "                            img_w, img_h)\n",
    "        \n",
    "        print(\"pred_image.shape =\", pred_image.shape)\n",
    "        print(\"image_gt_torch.shape =\", image_gt_torch.shape)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = image_loss(pred_image, image_gt_torch)\n",
    "        \n",
    "        # Backpropagation and optimization step.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Normalize quaternions to maintain valid unit quaternions.\n",
    "        with torch.no_grad():\n",
    "            q_norms = torch.norm(quaternions, dim=1, keepdim=True)\n",
    "            quaternions.data /= q_norms\n",
    "        \n",
    "        # Adaptive density control (densification & culling)\n",
    "        iteration += 1\n",
    "        if iteration > warmup_iters and (iteration % densify_interval == 0):\n",
    "            # Analyze position gradients to find Gaussians with large gradient magnitude.\n",
    "            pos_grads = positions.grad.detach().clone()  # shape (N, 3)\n",
    "            grad_mags = torch.norm(pos_grads, dim=1)\n",
    "            avg_grad = grad_mags.mean().item()\n",
    "            \n",
    "            gamma = max(0.5 * avg_grad, 1e-3)\n",
    "            high_grad_idx = (grad_mags > gamma).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # Prepare lists for indices to remove and new parameters for cloned/split Gaussians.\n",
    "            remove_idx = set()\n",
    "            new_positions_list = []\n",
    "            new_log_scales_list = []\n",
    "            new_quats_list = []\n",
    "            new_sh_list = []\n",
    "            new_alpha_param_list = []\n",
    "            \n",
    "            # Use volumes (product of scales) to decide cloning vs. splitting.\n",
    "            scales = torch.exp(log_scales.detach())  # (N, 3)\n",
    "            volumes = scales.prod(dim=1)             # approximate volume per Gaussian\n",
    "            vol_median = volumes.median().item()\n",
    "            \n",
    "            import math\n",
    "            \n",
    "            for idx in high_grad_idx.tolist():\n",
    "                if idx in remove_idx:\n",
    "                    continue\n",
    "                vol_i = volumes[idx].item()\n",
    "                if vol_i < vol_median:\n",
    "                    # **Clone**: Duplicate the Gaussian with a slight offset in the gradient direction.\n",
    "                    mu = positions.data[idx].clone()\n",
    "                    grad_dir = pos_grads[idx] / (grad_mags[idx] + 1e-8)\n",
    "                    offset_dist = 0.5 * scales[idx].mean().item()\n",
    "                    new_mu = mu + grad_dir * offset_dist\n",
    "                    \n",
    "                    new_positions_list.append(new_mu)\n",
    "                    new_log_scales_list.append(log_scales.data[idx].clone())\n",
    "                    new_quats_list.append(quaternions.data[idx].clone())\n",
    "                    new_sh_list.append(sh_coeffs.data[idx].clone())\n",
    "                    new_alpha_param_list.append(alpha_params.data[idx].clone())\n",
    "                else:\n",
    "                    # **Split**: Remove the original and replace it with two smaller Gaussians.\n",
    "                    remove_idx.add(idx)\n",
    "                    mu = positions.data[idx]\n",
    "                    quat_i = quaternions.data[idx]\n",
    "                    \n",
    "                    # For splitting, use the largest scale dimension.\n",
    "                    s = scales[idx]\n",
    "                    axis = torch.zeros(3, device=positions.device)\n",
    "                    largest_dim = torch.argmax(s).item()\n",
    "                    axis[largest_dim] = 1.0\n",
    "                    offset = axis * s[largest_dim].item()\n",
    "                    \n",
    "                    new_mu1 = mu + offset\n",
    "                    new_mu2 = mu - offset\n",
    "                    shrink_factor = (2**(1/3))  # approximately 1.26 to conserve volume.\n",
    "                    new_log_scale = log_scales.data[idx] - math.log(shrink_factor)\n",
    "                    \n",
    "                    new_quat = quaternions.data[idx].clone()\n",
    "                    new_sh   = sh_coeffs.data[idx].clone()\n",
    "                    new_alpha = alpha_params.data[idx].clone()\n",
    "                    \n",
    "                    new_positions_list.append(new_mu1.clone())\n",
    "                    new_positions_list.append(new_mu2.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "            \n",
    "            # Cull Gaussians with very low alpha (almost transparent).\n",
    "            alpha_vals = torch.sigmoid(alpha_params.detach())\n",
    "            trans_idx = (alpha_vals < 1e-3).nonzero(as_tuple=True)[0].tolist()\n",
    "            for idx in trans_idx:\n",
    "                remove_idx.add(idx)\n",
    "            \n",
    "            if remove_idx or new_positions_list:\n",
    "                remove_idx = sorted(remove_idx)\n",
    "                print(f\"[Densify] Removing {len(remove_idx)} gaussians, adding {len(new_positions_list)} gaussians\")\n",
    "                keep_mask = torch.ones_like(alpha_params, dtype=torch.bool)\n",
    "                keep_mask[remove_idx] = False\n",
    "                \n",
    "                positions.data    = positions.data[keep_mask]\n",
    "                log_scales.data   = log_scales.data[keep_mask]\n",
    "                quaternions.data  = quaternions.data[keep_mask]\n",
    "                sh_coeffs.data    = sh_coeffs.data[keep_mask]\n",
    "                alpha_params.data = alpha_params.data[keep_mask]\n",
    "                \n",
    "                if new_positions_list:\n",
    "                    new_positions    = torch.stack(new_positions_list, dim=0)\n",
    "                    new_log_scales   = torch.stack(new_log_scales_list, dim=0)\n",
    "                    new_quats        = torch.stack(new_quats_list, dim=0)\n",
    "                    new_sh           = torch.stack(new_sh_list, dim=0)\n",
    "                    new_alpha_params = torch.stack(new_alpha_param_list, dim=0)\n",
    "                    \n",
    "                    # Normalize the new quaternions.\n",
    "                    q_norms = torch.norm(new_quats, dim=1, keepdim=True)\n",
    "                    new_quats = new_quats / q_norms\n",
    "                    \n",
    "                    positions.data    = torch.cat([positions.data,    new_positions],    dim=0)\n",
    "                    log_scales.data   = torch.cat([log_scales.data,   new_log_scales],   dim=0)\n",
    "                    quaternions.data  = torch.cat([quaternions.data,  new_quats],        dim=0)\n",
    "                    sh_coeffs.data    = torch.cat([sh_coeffs.data,    new_sh],           dim=0)\n",
    "                    alpha_params.data = torch.cat([alpha_params.data, new_alpha_params], dim=0)\n",
    "                \n",
    "                # Update total number of Gaussians.\n",
    "                N = positions.shape[0]\n",
    "                # Recreate the optimizer parameter groups to match the new tensor sizes.\n",
    "                optimizer.param_groups = []\n",
    "                optimizer.add_param_group({'params': positions,    'lr': lr_pos})\n",
    "                optimizer.add_param_group({'params': log_scales,   'lr': lr_scale})\n",
    "                optimizer.add_param_group({'params': quaternions,  'lr': lr_quat})\n",
    "                optimizer.add_param_group({'params': sh_coeffs,    'lr': lr_sh})\n",
    "                optimizer.add_param_group({'params': alpha_params, 'lr': lr_alpha})\n",
    "\n",
    "print(\"Training loop complete (dummy version). Next, we need a real 'render()' to see meaningful updates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Optimization (Training) Code\n",
    "\n",
    "1. **Loss Function and Optimizer Setup:**  \n",
    "   - We define `image_loss()` as a simple mean squared error (MSE) loss between the predicted image and the ground truth.\n",
    "   - An Adam optimizer is created with separate learning rates for:\n",
    "     - Positions and log scales: \\(1 \\times 10^{-3}\\)\n",
    "     - Quaternions: \\(1 \\times 10^{-3}\\)\n",
    "     - SH color coefficients: \\(1 \\times 10^{-2}\\)\n",
    "     - Alpha parameters: \\(5 \\times 10^{-3}\\)\n",
    "\n",
    "2. **Placeholder Render Function:**  \n",
    "   - The `render()` function is currently a placeholder that returns a zero image of the correct shape.  \n",
    "   - We add a dependency on `positions` (via `positions.sum() * 0.0`) so that the output has a gradient function attached, allowing gradients to flow during backpropagation.\n",
    "\n",
    "3. **Training Loop:**  \n",
    "   - For each training image:\n",
    "     - The ground truth image is converted to a torch tensor on the appropriate device.\n",
    "     - The image's height and width are extracted directly from the ground truth, ensuring that the rendered image matches its shape.\n",
    "     - Camera intrinsics are extracted from the dataset (though camera extrinsics are currently placeholders set to identity and zero).\n",
    "     - The `render()` function is called to generate a predicted image.\n",
    "     - Shapes of the predicted and ground truth images are printed for debugging.\n",
    "     - The loss is computed using `image_loss()`, and backpropagation is performed.\n",
    "     - After the optimizer step, quaternions are re-normalized to maintain valid rotations.\n",
    "   \n",
    "4. **Adaptive Density Control (Densification):**  \n",
    "   - Every 100 iterations (after an initial 100-iteration warmup), the code analyzes the gradients of the positions to identify Gaussians with large errors.\n",
    "   - Based on the magnitude of the gradients and the computed \"volume\" (product of scales), Gaussians are either:\n",
    "     - **Cloned:** For small Gaussians, a duplicate is created with a small offset in the gradient direction.\n",
    "     - **Split:** For large Gaussians, the original is removed and replaced by two smaller Gaussians (with scales reduced by approximately a factor of 1.26).\n",
    "   - Gaussians with very low opacity (alpha near zero) are culled.\n",
    "   - Finally, the parameter tensors are updated to remove and add Gaussians, and the optimizer is reconfigured to match the new tensor sizes.\n",
    "   \n",
    "This code sets up a dummy training loop. Once we implement a real differentiable renderer, the loss will reflect the difference between rendered images and ground truth, allowing the Gaussian parameters to be optimized meaningfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiable Renderer (Rendering the Gaussian Radiance Field)\n",
    "\n",
    "The core of the Gaussian Splatting method is the differentiable renderer, which projects the 3D Gaussians to the image plane and blends them with proper ordering (front-to-back alpha compositing) for real-time rendering. This renderer is crucial for training the Gaussian radiance field and synthesizing novel views of the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def quaternion_to_rot_matrix(q):\n",
    "    \"\"\"\n",
    "    Convert a quaternion (w, x, y, z) to a 3x3 rotation matrix.\n",
    "    q is a tensor or numpy array of shape (4,).\n",
    "    \"\"\"\n",
    "    if isinstance(q, torch.Tensor):\n",
    "        q = q.detach().cpu().numpy()\n",
    "    w, x, y, z = q\n",
    "    n = math.sqrt(w*w + x*x + y*y + z*z)\n",
    "    if n < 1e-8:\n",
    "        return np.eye(3)\n",
    "    w, x, y, z = w/n, x/n, y/n, z/n\n",
    "    return np.array([\n",
    "        [1 - 2*(y*y + z*z), 2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1 - 2*(x*x + z*z), 2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w), 1 - 2*(x*x + y*y)]\n",
    "    ], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_extrinsics(pose, device):\n",
    "    \"\"\"\n",
    "    Given a pose tuple (qvec, tvec, cam_id) from COLMAP, return R_cam and t_cam as torch tensors.\n",
    "    In COLMAP, the pose transforms world coordinates to camera coordinates:\n",
    "      X_cam = R_cam @ X_world + t_cam.\n",
    "    \"\"\"\n",
    "    qvec, tvec, cam_id = pose\n",
    "    R_cam = torch.tensor(quaternion_to_rot_matrix(qvec), dtype=torch.float32, device=device)\n",
    "    t_cam = torch.tensor(tvec, dtype=torch.float32, device=device)\n",
    "    return R_cam, t_cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(R_cam, t_cam, fx, fy, cx, cy,\n",
    "           positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "           width, height, background_color=None):\n",
    "    \"\"\"\n",
    "    Render an image (width x height) from the current Gaussian splat scene.\n",
    "    \n",
    "    Parameters:\n",
    "    - R_cam, t_cam: Camera extrinsics (3x3 rotation, 3-element translation) as torch tensors.\n",
    "    - fx, fy, cx, cy: Camera intrinsics.\n",
    "    - positions, log_scales, quaternions, alpha_params, sh_coeffs: Learnable 3D Gaussian parameters.\n",
    "    - width, height: Output image dimensions.\n",
    "    - background_color: Optional background color as a tuple, e.g., (0, 0, 0).\n",
    "    \n",
    "    Returns:\n",
    "    - image: A tensor of shape [height, width, 3] with pixel values in [0, 1].\n",
    "    \n",
    "    This function performs:\n",
    "      1. Projection of each 3D Gaussian to the image.\n",
    "      2. Covariance projection via the Jacobian.\n",
    "      3. Evaluation of the 2D Gaussian (splat) and alpha blending.\n",
    "    \"\"\"\n",
    "    device = positions.device\n",
    "    \n",
    "    # Ensure R_cam and t_cam are on the correct device.\n",
    "    if not isinstance(R_cam, torch.Tensor):\n",
    "        R_cam = torch.tensor(R_cam, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        R_cam = R_cam.to(device)\n",
    "    if not isinstance(t_cam, torch.Tensor):\n",
    "        t_cam = torch.tensor(t_cam, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        t_cam = t_cam.to(device)\n",
    "    \n",
    "    image = torch.zeros((height, width, 3), device=device)\n",
    "    accum_alpha = torch.zeros((height, width), device=device)\n",
    "    \n",
    "    N = positions.shape[0]\n",
    "    alpha_vals = torch.sigmoid(alpha_params)\n",
    "    scale_vals = torch.exp(log_scales)\n",
    "    \n",
    "    n_basis = (2 + 1) ** 2  # 9 for 2nd-order SH\n",
    "    \n",
    "    for i in range(N):\n",
    "        mu_world = positions[i]  # (3,)\n",
    "        mu_cam = R_cam @ mu_world + t_cam  # (3,)\n",
    "        X, Y, Z = mu_cam[0].item(), mu_cam[1].item(), mu_cam[2].item()\n",
    "        if Z <= 1e-6:\n",
    "            continue\n",
    "        \n",
    "        u0 = fx * (X / Z) + cx\n",
    "        v0 = fy * (Y / Z) + cy\n",
    "        \n",
    "        if u0 < -100 or u0 > width+100 or v0 < -100 or v0 > height+100:\n",
    "            continue\n",
    "        \n",
    "        quat = quaternions[i].detach().cpu().numpy()\n",
    "        R_gauss = torch.tensor(quaternion_to_rot_matrix(quat), dtype=torch.float32, device=device)\n",
    "        R_combined = R_cam @ R_gauss\n",
    "        s_vals = scale_vals[i]\n",
    "        S2 = torch.diag(s_vals**2)\n",
    "        Sigma_cam = R_combined @ S2 @ R_combined.t()\n",
    "        \n",
    "        # Create Jacobian J with explicit dtype=float32.\n",
    "        J = torch.tensor([[fx / Z, 0.0, -fx * X / (Z*Z)],\n",
    "                          [0.0, fy / Z, -fy * Y / (Z*Z)]],\n",
    "                         dtype=torch.float32, device=device)\n",
    "        Sigma_img = J @ Sigma_cam @ J.t()  # 2x2 matrix\n",
    "        \n",
    "        A = Sigma_img[0,0].item()\n",
    "        B = Sigma_img[0,1].item()\n",
    "        C = Sigma_img[1,1].item()\n",
    "        det = A * C - B * B\n",
    "        if det <= 0:\n",
    "            invA = 1/(A+1e-6)\n",
    "            invB = 0\n",
    "            invC = 1/(C+1e-6)\n",
    "        else:\n",
    "            inv_det = 1.0 / det\n",
    "            invA = C * inv_det\n",
    "            invB = -B * inv_det\n",
    "            invC = A * inv_det\n",
    "        \n",
    "        trace = A + C\n",
    "        disc = (A - C)**2 + 4*(B**2)\n",
    "        if disc < 0:\n",
    "            disc = 0.0\n",
    "        eig1 = 0.5 * (trace + math.sqrt(disc))\n",
    "        sigma_max = math.sqrt(max(eig1, 0))\n",
    "        radius = 3 * sigma_max\n",
    "        u_min = int(math.floor(u0 - radius))\n",
    "        u_max = int(math.ceil(u0 + radius))\n",
    "        v_min = int(math.floor(v0 - radius))\n",
    "        v_max = int(math.ceil(v0 + radius))\n",
    "        u_min = max(0, u_min); u_max = min(width - 1, u_max)\n",
    "        v_min = max(0, v_min); v_max = min(height - 1, v_max)\n",
    "        if u_min > u_max or v_min > v_max:\n",
    "            continue\n",
    "        \n",
    "        # Compute view-dependent color using 2nd-order SH.\n",
    "        cam_center_world = -R_cam.t() @ t_cam\n",
    "        view_dir_world = cam_center_world - mu_world\n",
    "        view_dir_world = view_dir_world / torch.norm(view_dir_world)\n",
    "        view_dir_local = R_gauss.t() @ view_dir_world\n",
    "        vx, vy, vz = view_dir_local.detach().cpu().numpy().tolist()\n",
    "        Y00 = 0.282095\n",
    "        Y1m1 = 0.488603 * vy\n",
    "        Y10 = 0.488603 * vz\n",
    "        Y11 = 0.488603 * vx\n",
    "        Y20 = 0.315392 * (3*vz**2 - 1)\n",
    "        Y2m1 = 1.092548 * vy * vz\n",
    "        Y22 = 0.546274 * (vx**2 - vy**2)\n",
    "        Y21 = 1.092548 * vx * vz\n",
    "        Y2m2 = 1.092548 * vx * vy\n",
    "        sh_basis = [Y00, Y1m1, Y10, Y11, Y2m2, Y2m1, Y20, Y21, Y22]\n",
    "        sh_basis = torch.tensor(sh_basis, dtype=torch.float32, device=device)\n",
    "        coeff = sh_coeffs[i].view(3, n_basis)\n",
    "        color_i = coeff @ sh_basis\n",
    "        color_i = torch.clamp(color_i, 0.0, 1e3)\n",
    "        \n",
    "        alpha_i = alpha_vals[i].item()\n",
    "        \n",
    "        for py in range(v_min, v_max+1):\n",
    "            dy = (py + 0.5) - v0\n",
    "            for px in range(u_min, u_max+1):\n",
    "                dx = (px + 0.5) - u0\n",
    "                mahal = invA * dx*dx + 2 * invB * dx*dy + invC * dy*dy\n",
    "                weight = alpha_i * math.exp(-0.5 * mahal)\n",
    "                if weight < 1e-6:\n",
    "                    continue\n",
    "                if accum_alpha[py, px] >= 0.999:\n",
    "                    continue\n",
    "                remaining = 1.0 - accum_alpha[py, px].item()\n",
    "                add_alpha = remaining * weight\n",
    "                if add_alpha <= 0:\n",
    "                    continue\n",
    "                image[py, px] += add_alpha * color_i\n",
    "                accum_alpha[py, px] += add_alpha\n",
    "    if background_color is not None:\n",
    "        bg = torch.tensor(background_color, dtype=torch.float32, device=device)\n",
    "        image = image + (1 - accum_alpha[..., None]) * bg\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Rendering Function\n",
    "\n",
    "1. **Camera and Output Setup:**  \n",
    "   - The function converts the camera extrinsics (rotation \\(R_{cam}\\) and translation \\(t_{cam}\\)) to torch tensors on the correct device.\n",
    "   - It initializes an output image tensor (`image`) and an accumulator for per-pixel alpha (`accum_alpha`).\n",
    "\n",
    "2. **Processing Each Gaussian:**  \n",
    "   - For each Gaussian, the world-space center (`mu_world`) is transformed to camera space (`mu_cam`) using the camera extrinsics.\n",
    "   - The projected pixel coordinates \\((u_0, v_0)\\) are computed using the pinhole camera model:\n",
    "     \\[\n",
    "     u_0 = f_x \\cdot \\frac{X}{Z} + c_x, \\quad v_0 = f_y \\cdot \\frac{Y}{Z} + c_y\n",
    "     \\]\n",
    "   - Gaussians behind the camera or far outside the image bounds are skipped.\n",
    "\n",
    "3. **Covariance Projection:**  \n",
    "   - The Gaussian’s 3D covariance is constructed by combining its log scales (converted to actual scales) and its orientation (from the quaternion) using:\n",
    "     \\[\n",
    "     \\Sigma = R \\, \\mathrm{diag}(s_x^2, s_y^2, s_z^2) \\, R^T\n",
    "     \\]\n",
    "   - This covariance is transformed into camera space and then projected to the image plane using the Jacobian \\(J\\) of the projection. The resulting 2D covariance \\(\\Sigma_{img}\\) describes the ellipse (splat) on the image.\n",
    "\n",
    "4. **Evaluating the Splat:**  \n",
    "   - The inverse of \\(\\Sigma_{img}\\) is computed (with care taken if the determinant is near zero).\n",
    "   - A 3\\(\\sigma\\) bounding box is determined from the eigenvalues of \\(\\Sigma_{img}\\) to limit the pixel area over which the Gaussian contributes.\n",
    "   - For each pixel in this bounding box, the Mahalanobis distance is computed:\n",
    "     \\[\n",
    "     d^T \\Sigma_{img}^{-1} d\n",
    "     \\]\n",
    "   - The Gaussian weight at the pixel is:\n",
    "     \\[\n",
    "     w = \\alpha_i \\cdot \\exp\\left(-\\frac{1}{2} d^T \\Sigma_{img}^{-1} d\\right)\n",
    "     \\]\n",
    "     where \\(\\alpha_i\\) is the opacity.\n",
    "\n",
    "5. **View-Dependent Color:**  \n",
    "   - The viewing direction is computed from the camera center to the Gaussian center.\n",
    "   - This direction is transformed into the Gaussian’s local frame.\n",
    "   - The 2nd-order spherical harmonic (SH) basis functions are evaluated, and the corresponding SH coefficients (which represent color) are used to compute the final color for this Gaussian.\n",
    "\n",
    "6. **Alpha Blending:**  \n",
    "   - For each pixel, the color contribution is blended in a front-to-back manner:\n",
    "     - The effective contribution is weighted by the remaining transparency.\n",
    "     - If the accumulated alpha reaches nearly 1, further contributions are skipped.\n",
    "\n",
    "7. **Background Blending:**  \n",
    "   - If a background color is provided, it is blended into pixels that did not reach full opacity.\n",
    "   \n",
    "This implementation, though simplified and not optimized for speed, is fully differentiable so that gradients flow back to all Gaussian parameters. In a production system, further optimizations (such as tile-based culling and vectorized operations) would be applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Updated Training Loop Using Actual Camera Extrinsics ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Image 0, Loss: 0.1660\n",
      "Epoch 0, Image 1, Loss: 0.1565\n",
      "Epoch 0, Image 2, Loss: 0.1494\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "densify_interval = 100\n",
    "warmup_iters = 100\n",
    "losses = []\n",
    "\n",
    "\n",
    "train_images = scene_data[\"images\"]             # list of [H, W, 3] ground-truth images\n",
    "camera_info = scene_data[\"camera_intrinsics\"]     # list of (fx, fy, cx, cy, w, h) per image\n",
    "camera_poses = scene_data[\"camera_poses\"]           # list of (qvec, tvec, cam_id) per image\n",
    "\n",
    "iteration = 0\n",
    "device = positions.device\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for img_idx, image_gt in enumerate(train_images):\n",
    "        if image_gt is None:\n",
    "            continue\n",
    "        \n",
    "        image_gt_torch = torch.tensor(image_gt, dtype=torch.float32, device=device)\n",
    "        img_h, img_w = image_gt_torch.shape[0], image_gt_torch.shape[1]\n",
    "        \n",
    "        fx, fy, cx, cy, _, _ = camera_info[img_idx]\n",
    "        \n",
    "        pose = camera_poses[img_idx]  # (qvec, tvec, cam_id)\n",
    "        R_cam, t_cam = get_camera_extrinsics(pose, device)\n",
    "        \n",
    "        pred_image = render(R_cam, t_cam, fx, fy, cx, cy,\n",
    "                            positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "                            img_w, img_h, background_color=(0, 0, 0))\n",
    "        \n",
    "    \n",
    "        \n",
    "        loss = image_loss(pred_image, image_gt_torch)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Image {img_idx}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            q_norms = torch.norm(quaternions, dim=1, keepdim=True)\n",
    "            quaternions.data /= q_norms\n",
    "        \n",
    "        iteration += 1\n",
    "        if iteration > warmup_iters and (iteration % densify_interval == 0):\n",
    "            pos_grads = positions.grad.detach().clone()  # (N, 3)\n",
    "            grad_mags = torch.norm(pos_grads, dim=1)\n",
    "            avg_grad = grad_mags.mean().item()\n",
    "            gamma = max(0.5 * avg_grad, 1e-3)\n",
    "            high_grad_idx = (grad_mags > gamma).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            remove_idx = set()\n",
    "            new_positions_list = []\n",
    "            new_log_scales_list = []\n",
    "            new_quats_list = []\n",
    "            new_sh_list = []\n",
    "            new_alpha_param_list = []\n",
    "            \n",
    "            scales = torch.exp(log_scales.detach())  # (N,3)\n",
    "            volumes = scales.prod(dim=1)\n",
    "            vol_median = volumes.median().item()\n",
    "            \n",
    "            for idx in high_grad_idx.tolist():\n",
    "                if idx in remove_idx:\n",
    "                    continue\n",
    "                vol_i = volumes[idx].item()\n",
    "                if vol_i < vol_median:\n",
    "                    mu = positions.data[idx].clone()\n",
    "                    grad_dir = pos_grads[idx] / (grad_mags[idx] + 1e-8)\n",
    "                    offset_dist = 0.5 * scales[idx].mean().item()\n",
    "                    new_mu = mu + grad_dir * offset_dist\n",
    "                    new_positions_list.append(new_mu)\n",
    "                    new_log_scales_list.append(log_scales.data[idx].clone())\n",
    "                    new_quats_list.append(quaternions.data[idx].clone())\n",
    "                    new_sh_list.append(sh_coeffs.data[idx].clone())\n",
    "                    new_alpha_param_list.append(alpha_params.data[idx].clone())\n",
    "                else:\n",
    "                    remove_idx.add(idx)\n",
    "                    mu = positions.data[idx]\n",
    "                    s = scales[idx]\n",
    "                    axis = torch.zeros(3, device=device)\n",
    "                    largest_dim = torch.argmax(s).item()\n",
    "                    axis[largest_dim] = 1.0\n",
    "                    offset = axis * s[largest_dim].item()\n",
    "                    new_mu1 = mu + offset\n",
    "                    new_mu2 = mu - offset\n",
    "                    shrink_factor = (2**(1/3))\n",
    "                    new_log_scale = log_scales.data[idx] - math.log(shrink_factor)\n",
    "                    new_quat = quaternions.data[idx].clone()\n",
    "                    new_sh = sh_coeffs.data[idx].clone()\n",
    "                    new_alpha = alpha_params.data[idx].clone()\n",
    "                    new_positions_list.append(new_mu1.clone())\n",
    "                    new_positions_list.append(new_mu2.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "            \n",
    "            alpha_vals = torch.sigmoid(alpha_params.detach())\n",
    "            trans_idx = (alpha_vals < 1e-3).nonzero(as_tuple=True)[0].tolist()\n",
    "            for idx in trans_idx:\n",
    "                remove_idx.add(idx)\n",
    "            \n",
    "            if remove_idx or new_positions_list:\n",
    "                remove_idx = sorted(remove_idx)\n",
    "                print(f\"[Densify] Removing {len(remove_idx)} gaussians, adding {len(new_positions_list)} gaussians\")\n",
    "                keep_mask = torch.ones_like(alpha_params, dtype=torch.bool)\n",
    "                keep_mask[remove_idx] = False\n",
    "                positions.data = positions.data[keep_mask]\n",
    "                log_scales.data = log_scales.data[keep_mask]\n",
    "                quaternions.data = quaternions.data[keep_mask]\n",
    "                sh_coeffs.data = sh_coeffs.data[keep_mask]\n",
    "                alpha_params.data = alpha_params.data[keep_mask]\n",
    "                \n",
    "                if new_positions_list:\n",
    "                    new_positions = torch.stack(new_positions_list, dim=0)\n",
    "                    new_log_scales = torch.stack(new_log_scales_list, dim=0)\n",
    "                    new_quats = torch.stack(new_quats_list, dim=0)\n",
    "                    new_sh = torch.stack(new_sh_list, dim=0)\n",
    "                    new_alpha_params = torch.stack(new_alpha_param_list, dim=0)\n",
    "                    q_norms = torch.norm(new_quats, dim=1, keepdim=True)\n",
    "                    new_quats = new_quats / q_norms\n",
    "                    positions.data = torch.cat([positions.data, new_positions], dim=0)\n",
    "                    log_scales.data = torch.cat([log_scales.data, new_log_scales], dim=0)\n",
    "                    quaternions.data = torch.cat([quaternions.data, new_quats], dim=0)\n",
    "                    sh_coeffs.data = torch.cat([sh_coeffs.data, new_sh], dim=0)\n",
    "                    alpha_params.data = torch.cat([alpha_params.data, new_alpha_params], dim=0)\n",
    "                N = positions.shape[0]\n",
    "                optimizer.param_groups = []\n",
    "                optimizer.add_param_group({'params': positions, 'lr': lr_pos})\n",
    "                optimizer.add_param_group({'params': log_scales, 'lr': lr_scale})\n",
    "                optimizer.add_param_group({'params': quaternions, 'lr': lr_quat})\n",
    "                optimizer.add_param_group({'params': sh_coeffs, 'lr': lr_sh})\n",
    "                optimizer.add_param_group({'params': alpha_params, 'lr': lr_alpha})\n",
    "                \n",
    "print(\"Training loop complete (dummy version). Next, we need to refine the renderer and further optimize the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Optimization (Training) Code\n",
    "\n",
    "1. **Loss Function and Optimizer Setup:**  \n",
    "   - We define image_loss() as a simple mean squared error (MSE) loss between the predicted image and the ground truth.\n",
    "   - An Adam optimizer is created with separate learning rates for:\n",
    "     - Positions and log scales: \\(1 \\times 10^{-3}\\)\n",
    "     - Quaternions: \\(1 \\times 10^{-3}\\)\n",
    "     - SH color coefficients: \\(1 \\times 10^{-2}\\)\n",
    "     - Alpha parameters: \\(5 \\times 10^{-3}\\)\n",
    "\n",
    "2. **Placeholder Render Function:**  \n",
    "   - The render() function is currently a placeholder that returns a zero image of the correct shape.  \n",
    "   - We add a dependency on positions (via positions.sum() * 0.0) so that the output has a gradient function attached, allowing gradients to flow during backpropagation.\n",
    "\n",
    "3. **Training Loop:**  \n",
    "   - For each training image:\n",
    "     - The ground truth image is converted to a torch tensor on the appropriate device.\n",
    "     - The image's height and width are extracted directly from the ground truth, ensuring that the rendered image matches its shape.\n",
    "     - Camera intrinsics are extracted from the dataset (though camera extrinsics are currently placeholders set to identity and zero).\n",
    "     - The render() function is called to generate a predicted image.\n",
    "     - Shapes of the predicted and ground truth images are printed for debugging.\n",
    "     - The loss is computed using image_loss(), and backpropagation is performed.\n",
    "     - After the optimizer step, quaternions are re-normalized to maintain valid rotations.\n",
    "   \n",
    "4. **Adaptive Density Control (Densification):**  \n",
    "   - Every 100 iterations (after an initial 100-iteration warmup), the code analyzes the gradients of the positions to identify Gaussians with large errors.\n",
    "   - Based on the magnitude of the gradients and the computed \"volume\" (product of scales), Gaussians are either:\n",
    "     - **Cloned:** For small Gaussians, a duplicate is created with a small offset in the gradient direction.\n",
    "     - **Split:** For large Gaussians, the original is removed and replaced by two smaller Gaussians (with scales reduced by approximately a factor of 1.26).\n",
    "   - Gaussians with very low opacity (alpha near zero) are culled.\n",
    "   - Finally, the parameter tensors are updated to remove and add Gaussians, and the optimizer is reconfigured to match the new tensor sizes.\n",
    "   \n",
    "This code sets up a dummy training loop. Once we implement a real differentiable renderer, the loss will reflect the difference between rendered images and ground truth, allowing the Gaussian parameters to be optimized meaningfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiable Renderer (Rendering the Gaussian Radiance Field)\n",
    "\n",
    "The core of the Gaussian Splatting method is the differentiable renderer, which projects the 3D Gaussians to the image plane and blends them with proper ordering (front-to-back alpha compositing) for real-time rendering. This renderer is crucial for training the Gaussian radiance field and synthesizing novel views of the scene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_rot_matrix(q):\n",
    "    \"\"\"\n",
    "    Convert a quaternion (w, x, y, z) to a 3x3 rotation matrix.\n",
    "    q is a tensor or numpy array of shape (4,).\n",
    "    \"\"\"\n",
    "    if isinstance(q, torch.Tensor):\n",
    "        q = q.detach().cpu().numpy()\n",
    "    w, x, y, z = q\n",
    "    n = math.sqrt(w*w + x*x + y*y + z*z)\n",
    "    if n < 1e-8:\n",
    "        return np.eye(3)\n",
    "    w, x, y, z = w/n, x/n, y/n, z/n\n",
    "    return np.array([\n",
    "        [1 - 2*(y*y + z*z), 2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1 - 2*(x*x + z*z), 2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w), 1 - 2*(x*x + y*y)]\n",
    "    ], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(R_cam, t_cam, fx, fy, cx, cy,\n",
    "           positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "           width, height, background_color=None):\n",
    "    \"\"\"\n",
    "    Render an image (width x height) from the current Gaussian splat scene.\n",
    "    \n",
    "    Parameters:\n",
    "    - R_cam, t_cam: Camera extrinsics (3x3 rotation, 3-element translation) as torch tensors.\n",
    "    - fx, fy, cx, cy: Camera intrinsics.\n",
    "    - positions, log_scales, quaternions, alpha_params, sh_coeffs: Learnable 3D Gaussian parameters.\n",
    "    - width, height: Output image dimensions.\n",
    "    - background_color: Optional background color as a tuple, e.g., (0, 0, 0).\n",
    "    \n",
    "    Returns:\n",
    "    - image: A tensor of shape [height, width, 3] with pixel values in [0, 1].\n",
    "    \n",
    "    This function performs:\n",
    "      1. Projection of each 3D Gaussian to the image.\n",
    "      2. Covariance projection via the Jacobian.\n",
    "      3. Evaluation of the 2D Gaussian (splat) and alpha blending.\n",
    "    \"\"\"\n",
    "    device = positions.device\n",
    "    \n",
    "    # Ensure R_cam and t_cam are on the correct device.\n",
    "    if not isinstance(R_cam, torch.Tensor):\n",
    "        R_cam = torch.tensor(R_cam, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        R_cam = R_cam.to(device)\n",
    "    if not isinstance(t_cam, torch.Tensor):\n",
    "        t_cam = torch.tensor(t_cam, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        t_cam = t_cam.to(device)\n",
    "    \n",
    "    image = torch.zeros((height, width, 3), device=device)\n",
    "    accum_alpha = torch.zeros((height, width), device=device)\n",
    "    \n",
    "    N = positions.shape[0]\n",
    "    alpha_vals = torch.sigmoid(alpha_params)\n",
    "    scale_vals = torch.exp(log_scales)\n",
    "    \n",
    "    n_basis = (2 + 1) ** 2  # 9 for 2nd-order SH\n",
    "    \n",
    "    for i in range(N):\n",
    "        mu_world = positions[i]  # (3,)\n",
    "        mu_cam = R_cam @ mu_world + t_cam  # (3,)\n",
    "        X, Y, Z = mu_cam[0].item(), mu_cam[1].item(), mu_cam[2].item()\n",
    "        if Z <= 1e-6:\n",
    "            continue\n",
    "        \n",
    "        u0 = fx * (X / Z) + cx\n",
    "        v0 = fy * (Y / Z) + cy\n",
    "        \n",
    "        if u0 < -100 or u0 > width+100 or v0 < -100 or v0 > height+100:\n",
    "            continue\n",
    "        \n",
    "        quat = quaternions[i].detach().cpu().numpy()\n",
    "        R_gauss = torch.tensor(quaternion_to_rot_matrix(quat), dtype=torch.float32, device=device)\n",
    "        R_combined = R_cam @ R_gauss\n",
    "        s_vals = scale_vals[i]\n",
    "        S2 = torch.diag(s_vals**2)\n",
    "        Sigma_cam = R_combined @ S2 @ R_combined.t()\n",
    "        \n",
    "        # Create Jacobian J with explicit dtype=float32.\n",
    "        J = torch.tensor([[fx / Z, 0.0, -fx * X / (Z*Z)],\n",
    "                          [0.0, fy / Z, -fy * Y / (Z*Z)]],\n",
    "                         dtype=torch.float32, device=device)\n",
    "        Sigma_img = J @ Sigma_cam @ J.t()  # 2x2 matrix\n",
    "        \n",
    "        A = Sigma_img[0,0].item()\n",
    "        B = Sigma_img[0,1].item()\n",
    "        C = Sigma_img[1,1].item()\n",
    "        det = A * C - B * B\n",
    "        if det <= 0:\n",
    "            invA = 1/(A+1e-6)\n",
    "            invB = 0\n",
    "            invC = 1/(C+1e-6)\n",
    "        else:\n",
    "            inv_det = 1.0 / det\n",
    "            invA = C * inv_det\n",
    "            invB = -B * inv_det\n",
    "            invC = A * inv_det\n",
    "        \n",
    "        trace = A + C\n",
    "        disc = (A - C)**2 + 4*(B**2)\n",
    "        if disc < 0:\n",
    "            disc = 0.0\n",
    "        eig1 = 0.5 * (trace + math.sqrt(disc))\n",
    "        sigma_max = math.sqrt(max(eig1, 0))\n",
    "        radius = 3 * sigma_max\n",
    "        u_min = int(math.floor(u0 - radius))\n",
    "        u_max = int(math.ceil(u0 + radius))\n",
    "        v_min = int(math.floor(v0 - radius))\n",
    "        v_max = int(math.ceil(v0 + radius))\n",
    "        u_min = max(0, u_min); u_max = min(width - 1, u_max)\n",
    "        v_min = max(0, v_min); v_max = min(height - 1, v_max)\n",
    "        if u_min > u_max or v_min > v_max:\n",
    "            continue\n",
    "        \n",
    "        # Compute view-dependent color using 2nd-order SH.\n",
    "        cam_center_world = -R_cam.t() @ t_cam\n",
    "        view_dir_world = cam_center_world - mu_world\n",
    "        view_dir_world = view_dir_world / torch.norm(view_dir_world)\n",
    "        view_dir_local = R_gauss.t() @ view_dir_world\n",
    "        vx, vy, vz = view_dir_local.cpu().detach().numpy().tolist()\n",
    "        Y00 = 0.282095\n",
    "        Y1m1 = 0.488603 * vy\n",
    "        Y10 = 0.488603 * vz\n",
    "        Y11 = 0.488603 * vx\n",
    "        Y20 = 0.315392 * (3*vz**2 - 1)\n",
    "        Y2m1 = 1.092548 * vy * vz\n",
    "        Y22 = 0.546274 * (vx**2 - vy**2)\n",
    "        Y21 = 1.092548 * vx * vz\n",
    "        Y2m2 = 1.092548 * vx * vy\n",
    "        sh_basis = [Y00, Y1m1, Y10, Y11, Y2m2, Y2m1, Y20, Y21, Y22]\n",
    "        sh_basis = torch.tensor(sh_basis, dtype=torch.float32, device=device)\n",
    "        coeff = sh_coeffs[i].view(3, n_basis)\n",
    "        color_i = coeff @ sh_basis\n",
    "        color_i = torch.clamp(color_i, 0.0, 1e3)\n",
    "        \n",
    "        alpha_i = alpha_vals[i].item()\n",
    "        \n",
    "        for py in range(v_min, v_max+1):\n",
    "            dy = (py + 0.5) - v0\n",
    "            for px in range(u_min, u_max+1):\n",
    "                dx = (px + 0.5) - u0\n",
    "                mahal = invA * dx*dx + 2 * invB * dx*dy + invC * dy*dy\n",
    "                weight = alpha_i * math.exp(-0.5 * mahal)\n",
    "                if weight < 1e-6:\n",
    "                    continue\n",
    "                if accum_alpha[py, px] >= 0.999:\n",
    "                    continue\n",
    "                remaining = 1.0 - accum_alpha[py, px].item()\n",
    "                add_alpha = remaining * weight\n",
    "                if add_alpha <= 0:\n",
    "                    continue\n",
    "                image[py, px] += add_alpha * color_i\n",
    "                accum_alpha[py, px] += add_alpha\n",
    "    if background_color is not None:\n",
    "        bg = torch.tensor(background_color, dtype=torch.float32, device=device)\n",
    "        image = image + (1 - accum_alpha[..., None]) * bg\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_extrinsics(pose, device):\n",
    "    \"\"\"\n",
    "    Convert a COLMAP pose (qvec, tvec, cam_id) into R_cam and t_cam.\n",
    "    \"\"\"\n",
    "    qvec, tvec, cam_id = pose\n",
    "    R_cam = torch.tensor(quaternion_to_rot_matrix(qvec), dtype=torch.float32, device=device)\n",
    "    t_cam = torch.tensor(tvec, dtype=torch.float32, device=device)\n",
    "    return R_cam, t_cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Updated Training Loop Using Actual Camera Extrinsics ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Image 0, Loss: 0.1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Image 1, Loss: 0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Image 2, Loss: 0.1494\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "densify_interval = 100\n",
    "warmup_iters = 100\n",
    "loss = []\n",
    "\n",
    "train_images = scene_data[\"images\"]             # list of [H, W, 3] ground-truth images\n",
    "camera_info = scene_data[\"camera_intrinsics\"]     # list of (fx, fy, cx, cy, w, h) per image\n",
    "camera_poses = scene_data[\"camera_poses\"]           # list of (qvec, tvec, cam_id) per image\n",
    "\n",
    "iteration = 0\n",
    "device = positions.device\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for img_idx, image_gt in tqdm(enumerate(train_images)):\n",
    "        if image_gt is None:\n",
    "            continue\n",
    "        \n",
    "        image_gt_torch = torch.tensor(image_gt, dtype=torch.float32, device=device)\n",
    "        img_h, img_w = image_gt_torch.shape[0], image_gt_torch.shape[1]\n",
    "        \n",
    "        fx, fy, cx, cy, _, _ = camera_info[img_idx]\n",
    "        \n",
    "        pose = camera_poses[img_idx]  # (qvec, tvec, cam_id)\n",
    "        R_cam, t_cam = get_camera_extrinsics(pose, device)\n",
    "        \n",
    "        pred_image = render(R_cam, t_cam, fx, fy, cx, cy,\n",
    "                            positions, log_scales, quaternions, alpha_params, sh_coeffs,\n",
    "                            img_w, img_h, background_color=(0, 0, 0))\n",
    "        \n",
    "\n",
    "        \n",
    "        loss = image_loss(pred_image, image_gt_torch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Image {img_idx}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            q_norms = torch.norm(quaternions, dim=1, keepdim=True)\n",
    "            quaternions.data /= q_norms\n",
    "        \n",
    "        iteration += 1\n",
    "        if iteration > warmup_iters and (iteration % densify_interval == 0):\n",
    "            pos_grads = positions.grad.detach().clone()  # (N, 3)\n",
    "            grad_mags = torch.norm(pos_grads, dim=1)\n",
    "            avg_grad = grad_mags.mean().item()\n",
    "            gamma = max(0.5 * avg_grad, 1e-3)\n",
    "            high_grad_idx = (grad_mags > gamma).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            remove_idx = set()\n",
    "            new_positions_list = []\n",
    "            new_log_scales_list = []\n",
    "            new_quats_list = []\n",
    "            new_sh_list = []\n",
    "            new_alpha_param_list = []\n",
    "            \n",
    "            scales = torch.exp(log_scales.detach())  # (N,3)\n",
    "            volumes = scales.prod(dim=1)\n",
    "            vol_median = volumes.median().item()\n",
    "            \n",
    "            for idx in high_grad_idx.tolist():\n",
    "                if idx in remove_idx:\n",
    "                    continue\n",
    "                vol_i = volumes[idx].item()\n",
    "                if vol_i < vol_median:\n",
    "                    mu = positions.data[idx].clone()\n",
    "                    grad_dir = pos_grads[idx] / (grad_mags[idx] + 1e-8)\n",
    "                    offset_dist = 0.5 * scales[idx].mean().item()\n",
    "                    new_mu = mu + grad_dir * offset_dist\n",
    "                    new_positions_list.append(new_mu)\n",
    "                    new_log_scales_list.append(log_scales.data[idx].clone())\n",
    "                    new_quats_list.append(quaternions.data[idx].clone())\n",
    "                    new_sh_list.append(sh_coeffs.data[idx].clone())\n",
    "                    new_alpha_param_list.append(alpha_params.data[idx].clone())\n",
    "                else:\n",
    "                    remove_idx.add(idx)\n",
    "                    mu = positions.data[idx]\n",
    "                    s = scales[idx]\n",
    "                    axis = torch.zeros(3, device=device)\n",
    "                    largest_dim = torch.argmax(s).item()\n",
    "                    axis[largest_dim] = 1.0\n",
    "                    offset = axis * s[largest_dim].item()\n",
    "                    new_mu1 = mu + offset\n",
    "                    new_mu2 = mu - offset\n",
    "                    shrink_factor = (2**(1/3))\n",
    "                    new_log_scale = log_scales.data[idx] - math.log(shrink_factor)\n",
    "                    new_quat = quaternions.data[idx].clone()\n",
    "                    new_sh = sh_coeffs.data[idx].clone()\n",
    "                    new_alpha = alpha_params.data[idx].clone()\n",
    "                    new_positions_list.append(new_mu1.clone())\n",
    "                    new_positions_list.append(new_mu2.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_log_scales_list.append(new_log_scale.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_quats_list.append(new_quat.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_sh_list.append(new_sh.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "                    new_alpha_param_list.append(new_alpha.clone())\n",
    "            \n",
    "            alpha_vals = torch.sigmoid(alpha_params.detach())\n",
    "            trans_idx = (alpha_vals < 1e-3).nonzero(as_tuple=True)[0].tolist()\n",
    "            for idx in trans_idx:\n",
    "                remove_idx.add(idx)\n",
    "            \n",
    "            if remove_idx or new_positions_list:\n",
    "                remove_idx = sorted(remove_idx)\n",
    "                print(f\"[Densify] Removing {len(remove_idx)} gaussians, adding {len(new_positions_list)} gaussians\")\n",
    "                keep_mask = torch.ones_like(alpha_params, dtype=torch.bool)\n",
    "                keep_mask[remove_idx] = False\n",
    "                positions.data = positions.data[keep_mask]\n",
    "                log_scales.data = log_scales.data[keep_mask]\n",
    "                quaternions.data = quaternions.data[keep_mask]\n",
    "                sh_coeffs.data = sh_coeffs.data[keep_mask]\n",
    "                alpha_params.data = alpha_params.data[keep_mask]\n",
    "                \n",
    "                if new_positions_list:\n",
    "                    new_positions = torch.stack(new_positions_list, dim=0)\n",
    "                    new_log_scales = torch.stack(new_log_scales_list, dim=0)\n",
    "                    new_quats = torch.stack(new_quats_list, dim=0)\n",
    "                    new_sh = torch.stack(new_sh_list, dim=0)\n",
    "                    new_alpha_params = torch.stack(new_alpha_param_list, dim=0)\n",
    "                    q_norms = torch.norm(new_quats, dim=1, keepdim=True)\n",
    "                    new_quats = new_quats / q_norms\n",
    "                    positions.data = torch.cat([positions.data, new_positions], dim=0)\n",
    "                    log_scales.data = torch.cat([log_scales.data, new_log_scales], dim=0)\n",
    "                    quaternions.data = torch.cat([quaternions.data, new_quats], dim=0)\n",
    "                    sh_coeffs.data = torch.cat([sh_coeffs.data, new_sh], dim=0)\n",
    "                    alpha_params.data = torch.cat([alpha_params.data, new_alpha_params], dim=0)\n",
    "                N = positions.shape[0]\n",
    "                optimizer.param_groups = []\n",
    "                optimizer.add_param_group({'params': positions, 'lr': lr_pos})\n",
    "                optimizer.add_param_group({'params': log_scales, 'lr': lr_scale})\n",
    "                optimizer.add_param_group({'params': quaternions, 'lr': lr_quat})\n",
    "                optimizer.add_param_group({'params': sh_coeffs, 'lr': lr_sh})\n",
    "                optimizer.add_param_group({'params': alpha_params, 'lr': lr_alpha})\n",
    "                \n",
    "print(\"Training loop complete (dummy version). Next, we need to refine the renderer and further optimize the pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d-mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
